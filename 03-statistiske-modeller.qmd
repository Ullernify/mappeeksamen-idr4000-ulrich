---
title: "Statistisk inferens"


editor_options: 
  chunk_output_type: console
---



## Simulering 
I denne rapporten benyttes [@RCoreTeam2021] til å simulere en populasjon på 1 million med et gjennomsnitt på 1.5 og et standaravvik på 3. For å kunne reprodusere resultatene benyttes set.seed(1). Deretter skapes det to studier hvor det trekkes to tilfeldige utvalg, et på 8 (samp1) og et på 40 (samp2). Videre lages en lineær modell for samp1 og samp2 som lagres som m1 og m2.

Alle oppgavene er utført i [@RCoreTeam2021] og koden vil bli vist på siste side.

```{r}
#| echo: false
#| message: false
#| warning: false

library(tidyverse)

# Muliggjør reproduksjon av resultater
set.seed(1)

# Simuler en populajson
population <- rnorm(1000000, mean = 1.5, sd = 3)

# Lag en studie med et utvalg på 8 hvor den avhengige variabelen heter y
samp1 <- data.frame(y = sample(population, 8, replace = FALSE))

# Lag en studie med et utvalg på 40 hvor den avhengige variabelen heter y
samp2 <- data.frame(y = sample(population, 40, replace = FALSE))

# Lag en lineær modell fra utvalg 1 og lagre den som m1
m1 <- lm(y ~ 1, data = samp1)
# Lag en lineær modell fra utvalg 2 og lagre den som m2
m2 <- lm(y ~ 1, data = samp2)


est_8 <- coef(m1)[1]
est_40 <- coef(m2)[1]




``` 

##  Forklaring av "estimate", "Standardfeil", "t-verdi" og "p-verdi" fra m1 og m2

Estimatet er en kalkulert teoretisk verdi av snittet til samp1 (`r round(est_8, digits = 3)`) og samp2 (`r round(est_40, digits = 3)`).
Standard feil er estimert variasjon i utvalgets gjennomsnitt. Dette forteller oss hvor presist gjennomsnittet fra utvalget estimerer populasjonens sanne gjennomsnitt. I dette tilfellet 1.251 (m1) og 0.4774 (m2). 
T-verdiene er 1.47 (m1) og 3.276 (m2). m1 i dette tilfellet sier at gjennomsnittet (1.840) er 1.47 standardfeil unna null noe som forteller oss at snittet ikke er signifikant (når signifikansnivå = p < 0.05) forskjellig fra nullhypotesen. P-verdien på 0.185 (m1) og 0.002 (m2) viser sannsynligheten for å få en t-verdi like ekstrem eller mer ekstrem enn den observerte t-verdien, gitt at nullhypotesen er sann. P-verdien regnes ut fra t-verdien og antall frihetsgrader og sier i dette tilfellet (m1) at det er 18.5% sannsynlighet for å få en t-verdi på 1.47 eller mer ekstrem gitt at nullhypotesten er sann. I tilfellet til (m1) kastes derfor ikke nullhypotesen. 



##  Hvorfor forkjellig resultat i m1 og m2?

Størrelsen på utvalget gir forskjellig avvik fra gjennomsnittet. m1 med et utvalg på 8 har større standardfeil da det er større sannsynlighet for at det er større variasjon i utvalget. Slik jeg forstår det vil en "uteligger" i en studie hvor N = 8 øker variansen i gjennomsnittet i større grad og derfor gi større utslag på standardfeilen. Dette fører igjen til en høyere p-verdi.

##  Hvorfor bruker vi det skraverte området i nedre og øvre del av en t-fordeling?

Det skraverte området i en t-fordeling visualiserer sannsynligheten for å få en verdi dersom nullhypotesen er sann. Dette brukes i hypotesetesting for å si at et resultat er signifikant forskjellig fra null. 

P-verdien beregnes som sannsynligheten i halen(e) av t-fordelingen basert på teststatistikken (
t-verdien). Et gitt signifikansnivå, ofte satt til p < 0.05, avgjør om resultatet anses som statistisk signifikant. For en tosidig test betyr dette at t-verdien må falle utenfor de sentrale 95 % av t-fordelingen (dvs. i de ytterste 2.5 % i hver hale) for å bli ansett som signifikant forskjellig fra null.


## Repeterte studier

I de neste oppgavene simuleres studiene 1000 ganger, og lagres deretter som results_8 og results_40.

```{r}
#| echo: false 
#| message: false
#| warning: false

set.seed(1)
# Create data frames to store the model estimates
results_8 <- data.frame(estimate = rep(NA, 1000), 
                      se = rep(NA, 1000), 
                      pval = rep(NA, 1000), 
                      n = 8)  

results_40 <- data.frame(estimate = rep(NA, 1000), 
                      se = rep(NA, 1000), 
                      pval = rep(NA, 1000), 
                      n = 40)

# A for loop used to sample 1000 studies, each iteration (i) will draw a new sample
# from the population. 

for(i in 1:1000) {
  
  # Draw a sample 
  samp1 <- data.frame(y = sample(population, 8, replace = FALSE))
  samp2 <- data.frame(y = sample(population, 40, replace = FALSE))

  # Model the data
  m1 <- lm(y ~ 1, data = samp1)
  m2 <- lm(y ~ 1, data = samp2)
  
  # Extract values from the models
  results_8[i, 1] <- coef(summary(m1))[1, 1]
  results_8[i, 2] <- coef(summary(m1))[1, 2]
  results_8[i, 3] <- coef(summary(m1))[1, 4]

  results_40[i, 1] <- coef(summary(m2))[1, 1]
  results_40[i, 2] <- coef(summary(m2))[1, 2]
  results_40[i, 3] <- coef(summary(m2))[1, 4]
  
  
}


# Save the results in a combined data frame

results <- bind_rows(results_8, results_40)

# Utregning standardavvik av estimert gjennomsnitt
sd_res_8 <- sd(results_8$estimate)
sd_res_40 <- sd(results_40$estimate)

# Utregning gjennomsnitt av standardfeil
se_mean_8 <- mean(results_8$se)
se_mean_40 <- mean(results_40$se)




```

##  Hvorfor er sandardavviket til estimert gjennomsnitt så lik standardfeilen i dette tilfellet?

Standardavviket til variabelen estimate, i simuleringen hvor n = 8 (sim8) og n = 40 (sim40), er `r round(sd_res_8, digits = 3)` og `r round(sd_res_40, digits = 3)`. Gjennomsnittlig standardfeil for sim8 og sim40 er `r round(se_mean_8, digits = 3)` og `r round(se_mean_40, digits = 3)`. Standardavviket samsvarer godt med standardfeilen fordi studiene nå er gjort 1000 ganger med tilfeldige utvalg fra populasjonen. Dette fanger opp mer av populasjonens egenskaper og standardavviket vil nærmer seg en teoretisk fordeling.

Grunnen til at standardavviket og standardfeilen er større ved små utvalg er at variasjonen mellom gjennomsnittene er større.  



## Histogram med p-verdier fra simuleringene, hva sier dette om statistisk styrke?

```{r}
#| echo: false
#| message: false
#| warning: false


# Example code for copy and paste

# A two facets histogram can be created with ggplot2
results %>%
  ggplot(aes(pval)) + 
  geom_histogram(color = "red") +
  facet_wrap(~ n)


# Count the proportion of tests below a certain p-value for each 
sig_results <-results %>%
  filter(pval < 0.05) %>%
  group_by(n) 
 


```
Histogrammene viser fordelingen av p-verdier fra studiene. P-verdiene fra studiene gjort med et utvalg på 8 har en bredere fordeling enn studiene gjort med utvalg på 40. Mindre utvalg er mer følsomme for variasjon i dataen, uteliggere og større spredning viser seg som større spredning i p-verdier. Mindre utvalg vil i tillegg gi lavere presisjon og redusere sannsynligheten for signifikante resultater. 

Større utvalg vil derimot oftere føre til lavere p-verdi. Det større utvalget vil også gi en lavere standardfeil da variasjonen i gjennomsnittet reduseres. Et større utvalg er også mindre følsomt for uteliggere og vil gi en høyere t-verdi selv med lik effektstørrelse. Detta kan leses som større statistisk styrke.

##  Filtrer resultater med en gitt p-verdi

```{r}
#| echo: false
#| message: false
#| warning: false
n_sig_8 <- results %>% 
  filter(pval < 0.05) %>% 
  filter(n != 40) %>% 
  nrow()

n_sig_40 <- results %>% 
  filter(pval < 0.05) %>% 
  filter(n == 40) %>% 
  nrow()
```

Av 1000 studier simulert med et utvlag på 8 hadde `r n_sig_8` studier p < 0.05. Med et utvalg på 40 var det `r n_sig_40` studier med p < 0.05.

##  Test av statistisk styrke


```{r}
#| echo: false
#| message: false
#| warning: false

library(pwr)

pwr_40 <- pwr.t.test(n = 40, sig.level = 0.05, d = 1.5/3, type = "one.sample")
pwr_8 <- pwr.t.test(n = 8, sig.level = 0.05, d= 1.5/3, type = "one.sample")

numeric_pwr_40 <- pwr_40[["power"]]
pwr_pros_40 <- numeric_pwr_40 * 100

numeric_pwr_8 <- pwr_8[["power"]]
pwr_pros_8 <- numeric_pwr_8 * 100
```
Testing av statistisk styrke er gjort  med pakken "pwr". 

Styrken til studiene gjort med utvalg på 40 er `r round(pwr_pros_40, digits = 0)`% og et utvalg med 8 er `r round(pwr_pros_8, digits = 0)`%. Dette vil si at studiene gjort med utvalg på 40 har `r round(pwr_pros_40, digits = 0)`% sannsynlighet for å oppdage opp en effekt om det er en effekt. En høy (87%) statistisk styrke  vil også si at man har lav (13%) sannsynlighet for type-2 feil, å ikke oppdage en effekt dersom den finnes.  

##  Hvor mange studier gir falsk positiv når signifikansnivået er satt til 5%?

```{r}
#| echo: false
#| message: false
#| warning: false
set.seed(1)

population <- rnorm(1000000, mean = 0, sd = 3)


# Create data frames to store the model estimates
results_8 <- data.frame(estimate = rep(NA, 1000), 
                      se = rep(NA, 1000), 
                      pval = rep(NA, 1000), 
                      n = 8)  

results_40 <- data.frame(estimate = rep(NA, 1000), 
                      se = rep(NA, 1000), 
                      pval = rep(NA, 1000), 
                      n = 40)

# A for loop used to sample 1000 studies, each iteration (i) will draw a new sample
# from the population. 

for(i in 1:1000) {
  
  # Draw a sample 
  samp1 <- data.frame(y = sample(population, 8, replace = FALSE))
  samp2 <- data.frame(y = sample(population, 40, replace = FALSE))

  # Model the data
  m1 <- lm(y ~ 1, data = samp1)
  m2 <- lm(y ~ 1, data = samp2)

  # Extract values from the models
  results_8[i, 1] <- coef(summary(m1))[1, 1]
  results_8[i, 2] <- coef(summary(m1))[1, 2]
  results_8[i, 3] <- coef(summary(m1))[1, 4]

  results_40[i, 1] <- coef(summary(m2))[1, 1]
  results_40[i, 2] <- coef(summary(m2))[1, 2]
  results_40[i, 3] <- coef(summary(m2))[1, 4]
  
  
}


# Save the results in a combined data frame

results_null <- bind_rows(results_8, results_40)

false_positive_resnull <- sum(results_null$pval <0.05)

results_null %>%
  ggplot(aes(pval)) + 
  geom_histogram(color = "red") +
  facet_wrap(~ n)

n_sig_rnull_40 <- results_null %>% 
  filter(pval < 0.05) %>% 
  filter(n == 40) %>% 
  nrow()

n_sig_rnull_8 <- results_null %>% 
  filter(pval < 0.05) %>% 
  filter(n != 40) %>% 
  nrow()

```

Hvis man gjør mange repeterte studier med utvalg på 40 kan man anta at `r n_sig_rnull_40` er falsk positiv og `r n_sig_rnull_8` for utvalg på 8 dersom signifikansnivået er satt til 5%. Disse tallene er derfor å forvente etter 1000 simulerte studier da 5% = 50. Med signifikansnivå satt til 5% vil det si at vi tillater 5% sannsynlighet for å gjøre type-1 feil, altså å kaste nullhypotesen selv om den er sann. 

\newpage

```{r}
#| echo: true
#| message: false
#| warning: false

#Simulering 

library(tidyverse)

# Muliggjør reproduksjon av resultater
set.seed(1)

# Simuler en populajson
population <- rnorm(1000000, mean = 1.5, sd = 3)

# Lag en studie med et utvalg på 8 hvor den avhengige variabelen heter y
samp1 <- data.frame(y = sample(population, 8, replace = FALSE))

# Lag en studie med et utvalg på 40 hvor den avhengige variabelen heter y
samp2 <- data.frame(y = sample(population, 40, replace = FALSE))

# Lag en lineær modell fra utvalg 1 og lagre den som m1
m1 <- lm(y ~ 1, data = samp1)
# Lag en lineær modell fra utvalg 2 og lagre den som m2
m2 <- lm(y ~ 1, data = samp2)


est_8 <- coef(m1)[1]
est_40 <- coef(m2)[1]




``` 

```{r}
#| echo: true 
#| message: false
#| warning: false

#Repeterte studier

set.seed(1)
# Create data frames to store the model estimates
results_8 <- data.frame(estimate = rep(NA, 1000), 
                      se = rep(NA, 1000), 
                      pval = rep(NA, 1000), 
                      n = 8)  

results_40 <- data.frame(estimate = rep(NA, 1000), 
                      se = rep(NA, 1000), 
                      pval = rep(NA, 1000), 
                      n = 40)

# A for loop used to sample 1000 studies, each iteration (i) will draw a new sample
# from the population. 

for(i in 1:1000) {
  
  # Draw a sample 
  samp1 <- data.frame(y = sample(population, 8, replace = FALSE))
  samp2 <- data.frame(y = sample(population, 40, replace = FALSE))

  # Model the data
  m1 <- lm(y ~ 1, data = samp1)
  m2 <- lm(y ~ 1, data = samp2)
  
  # Extract values from the models
  results_8[i, 1] <- coef(summary(m1))[1, 1]
  results_8[i, 2] <- coef(summary(m1))[1, 2]
  results_8[i, 3] <- coef(summary(m1))[1, 4]

  results_40[i, 1] <- coef(summary(m2))[1, 1]
  results_40[i, 2] <- coef(summary(m2))[1, 2]
  results_40[i, 3] <- coef(summary(m2))[1, 4]
  
  
}


# Save the results in a combined data frame

results <- bind_rows(results_8, results_40)

# Utregning standardavvik av estimert gjennomsnitt
sd_res_8 <- sd(results_8$estimate)
sd_res_40 <- sd(results_40$estimate)

# Utregning gjennomsnitt av standardfeil
se_mean_8 <- mean(results_8$se)
se_mean_40 <- mean(results_40$se)




```

```{r}
#| echo: false
#| message: false
#| warning: false


# Histogram med p-verdier fra simuleringene, hva sier dette om statistisk styrke?

# A two facets histogram can be created with ggplot2
results %>%
  ggplot(aes(pval)) + 
  geom_histogram(color = "red") +
  facet_wrap(~ n)


# Count the proportion of tests below a certain p-value for each 
sig_results <-results %>%
  filter(pval < 0.05) %>%
  group_by(n) 
 


```

```{r}
#| echo: true
#| message: false
#| warning: false

# Filtrer resultater med en gitt p-verdi

n_sig_8 <- results %>% 
  filter(pval < 0.05) %>% 
  filter(n != 40) %>% 
  nrow()

n_sig_40 <- results %>% 
  filter(pval < 0.05) %>% 
  filter(n == 40) %>% 
  nrow()
```

```{r}
#| echo: true
#| message: false
#| warning: false

# Test av statistisk styrke
library(pwr)

pwr_40 <- pwr.t.test(n = 40, sig.level = 0.05, d = 1.5/3, type = "one.sample")
pwr_8 <- pwr.t.test(n = 8, sig.level = 0.05, d= 1.5/3, type = "one.sample")

numeric_pwr_40 <- pwr_40[["power"]]
pwr_pros_40 <- numeric_pwr_40 * 100

numeric_pwr_8 <- pwr_8[["power"]]
pwr_pros_8 <- numeric_pwr_8 * 100
```

```{r}
#| echo: true
#| message: false
#| warning: false

# Hvor mange studier gir falsk positiv når signifikansnivået er satt til 5%?
set.seed(1)

population <- rnorm(1000000, mean = 0, sd = 3)


# Create data frames to store the model estimates
results_8 <- data.frame(estimate = rep(NA, 1000), 
                      se = rep(NA, 1000), 
                      pval = rep(NA, 1000), 
                      n = 8)  

results_40 <- data.frame(estimate = rep(NA, 1000), 
                      se = rep(NA, 1000), 
                      pval = rep(NA, 1000), 
                      n = 40)

# A for loop used to sample 1000 studies, each iteration (i) will draw a new sample
# from the population. 

for(i in 1:1000) {
  
  # Draw a sample 
  samp1 <- data.frame(y = sample(population, 8, replace = FALSE))
  samp2 <- data.frame(y = sample(population, 40, replace = FALSE))

  # Model the data
  m1 <- lm(y ~ 1, data = samp1)
  m2 <- lm(y ~ 1, data = samp2)

  # Extract values from the models
  results_8[i, 1] <- coef(summary(m1))[1, 1]
  results_8[i, 2] <- coef(summary(m1))[1, 2]
  results_8[i, 3] <- coef(summary(m1))[1, 4]

  results_40[i, 1] <- coef(summary(m2))[1, 1]
  results_40[i, 2] <- coef(summary(m2))[1, 2]
  results_40[i, 3] <- coef(summary(m2))[1, 4]
  
  
}


# Save the results in a combined data frame

results_null <- bind_rows(results_8, results_40)

false_positive_resnull <- sum(results_null$pval <0.05)

results_null %>%
  ggplot(aes(pval)) + 
  geom_histogram(color = "red") +
  facet_wrap(~ n)

n_sig_rnull_40 <- results_null %>% 
  filter(pval < 0.05) %>% 
  filter(n == 40) %>% 
  nrow()

n_sig_rnull_8 <- results_null %>% 
  filter(pval < 0.05) %>% 
  filter(n != 40) %>% 
  nrow()

```




